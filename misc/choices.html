<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>Choices</title>
  	<link rel="stylesheet" href="../styles/mystyles.css">
	<link rel="preconnect" href="https://fonts.gstatic.com">
	<link href="https://fonts.googleapis.com/css2?family=Padauk&display=swap" rel="stylesheet">
  </head>

<body>
<!-- Site navigation menu -->

<ul class="navbar">
  <li><a href="../index.html">Home page</a>
  <li><a href="topic.html">Technology/Topic</a>
	<li><a href="opportunities.html">Opportunities</a>
	<li><a href="risks.html">Risks</a>
	<li><a class="current" href="choices.html">Choices</a>
	<li><a href="ethics.html">Ethical Reflections</a>
	<li><a href="references.html">References</a>
   <li><a href="process.html">Process Support</a>
</ul>

<!-- Main content -->
<h1>Possible Future Impacts of Artificial Intelligence</h1>

<h4>Progress of Artificial Intelligence</h4>
<p>Not every field of artificial intelligence is moving at the same pace or movement. Some fields move faster than the others. 
	For instance, the field of motor design, materials, and other parts that contributing to the physical capabilities of robots 
	have been rather slow. In contrast, the field of software programs such as machine learning is moving rather quickly. 
	Sometimes new concepts or algorithms create tremendous progress, but often cannot be said for sure, advancement of networking, 
	computing, storage, communication or data availability opens up the opportunity to develop artificial intelligence techniques 
	that may exploit the advancement.  To put into perspective, the progresses of artificial intelligence occur as a result of 
	advancements in specific fields by leveraging advances in software technologies and fundamental hardware (Kaplan, 2016).</p>

<h4>Benefits and risks of making robots and computers that act like people</h4>
<p>Despite knowing whether or not computers or machines can actually have feelings, it is very much possible to generate devices 
	that has specific characteristic such as having emotions. Project by Cynthia Breazeal at MIT in the year 1990s was successfully 
	implemented how robots can understand emotions such as excitement, surprise, delight, shame, disappointment, including fear, 
	among other emotions, through movements of lips, eyes, ears, eyebrows, and head. With this example we can say that computers or 
	robots are getting closer to mirror humanâ€™s behavior. One of the benefits of possible future impacts of artificial intelligence 
	is that the creation of these robots or machines can be programmed to be appealing to the society in a friendly and safe manners 
	which could result in human having more companions. There is also a major issue regarding having these intelligent and friendly 
	devices. People can become so attached to these artificial intelligence technologies that they may put the needs of others than 
	their own, they can more affections towards the machines or technologies than actual human beings (Kaplan, 2016).</p>

<h4>Can artificial intelligence programs such as machines or robots go wild?</h4>
<p>Based on the book by Kaplan (2016), the possibility of artificial intelligence systems go wild is very real. The objective of 
	having artificial intelligence projects is that having these systems operate without the help of human supervision or 
	intervention which should allow them to make independent decisions on their own. If the programmer or designer has not 
	carefully matched the capabilities of the systems to the operational bounds of their calculated or intentional use, it is 
	very much possible for the machines or robots to go out of control and cause significant damage. And a slight design or 
	technical failure could potentially create those destructive actions.</p>

<h4>How to minimize future risks?</h4>
<p>The most significant step is to establish professional and engineering standards for the examination and growth of these 
	intelligent systems. Artificial intelligence designers, researchers, or developers should be required to specify the operating 
	case of their creations which can be expected to work, and when the intended plans of these systems do not go their ways, all 
	the people involved in the making of these creations should incorporate ways to diminish the damages that these systems may cause. 
	Artificial intelligent systems should be implemented that they are capable to self-monitor their behavior and if the intended 
	actions do go out of the intended perimeters they should be able to shut down themselves, simply put going into safe mode 
	(Kaplan, 2016).</br>
	To conclude, these artificial intelligence systems do not have to actually have a sense of moral; they just have to be created 
	to behavior in ethically tolerable ways.
	</p>
<!-- Sign and date the page, it's only polite! -->
<address>Made 1 March 2021<br>
  by Team 1406.</address>
  </html>
